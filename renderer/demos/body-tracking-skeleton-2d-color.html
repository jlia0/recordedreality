<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
    <title>Kinect Azure Example</title>
    <link rel="stylesheet" href="../assets/vendors/bootstrap-4.3.1-dist/css/bootstrap.css">
    <link rel="stylesheet" href="../assets/vendors/bootstrap-4.3.1-dist/css/docs.min.css">
  </head>
  <body class="container-fluid py-3">
    <div class="d-flex align-items-baseline justify-content-between">
        <h1 class="bd-title">Body Tracking (2D)</h1>
        <button onclick="require('electron').remote.getCurrentWebContents().openDevTools()">open dev tools</button>
      </div>
      <p>
        This demo shows the 2D Skeleton Information.
      </p>
    <canvas id="outputCanvas" class="img-fluid"></canvas>
    <div class="row">
      <div class="col col-auto">Renderer: <div id="statsRenderer"></div></div>
      <div class="col col-auto">Kinect: <div id="statsKinect"></div></div>
    </div>
    
    <script src="../assets/vendors/stats.min.js"></script>
    <script>
      {
        const statsRenderer = new Stats();
        statsRenderer.dom.style.cssText = '';
        document.getElementById('statsRenderer').appendChild( statsRenderer.dom );
        const statsKinect = new Stats();
        statsKinect.dom.style.cssText = '';
        document.getElementById('statsKinect').appendChild( statsKinect.dom );

        const KinectAzure = require('kinect-azure');
        const kinect = new KinectAzure();

        const $outputCanvas = document.getElementById('outputCanvas'),
          outputCtx = $outputCanvas.getContext('2d');
        let outputImageData, depthModeRange;

        const init = () => {
          startKinect();
          animate();
        };

        const startKinect = () => {
          if(kinect.open()) {

            kinect.startCameras({
              depth_mode: KinectAzure.K4A_DEPTH_MODE_NFOV_UNBINNED,
              color_format: KinectAzure.K4A_IMAGE_FORMAT_COLOR_BGRA32,
              color_resolution: KinectAzure.K4A_COLOR_RESOLUTION_720P,
            });
            depthModeRange = kinect.getDepthModeRange(KinectAzure.K4A_DEPTH_MODE_NFOV_UNBINNED);
            kinect.createTracker({
              processing_mode: KinectAzure.K4ABT_TRACKER_PROCESSING_MODE_GPU_CUDA
            });

            kinect.startListening((data) => {
              statsKinect.update();
              if (!outputImageData && data.colorImageFrame.width > 0) {
                $outputCanvas.width = data.colorImageFrame.width;
                $outputCanvas.height = data.colorImageFrame.height;
                outputImageData = outputCtx.createImageData($outputCanvas.width, $outputCanvas.height);
              }
              if (outputImageData) {
                renderBGRA32ColorFrame(outputCtx, outputImageData, data.colorImageFrame);
              }
              if (data.bodyFrame.bodies) {
                // render the skeleton joints on top of the depth feed
                outputCtx.save();
                data.bodyFrame.bodies.forEach(body => {
                  outputCtx.fillStyle = 'red';
                  body.skeleton.joints.forEach(joint => {
                    outputCtx.fillRect(joint.colorX, joint.colorY, 10, 10);
                  });
                  // draw the pelvis as a green square
                  const pelvis = body.skeleton.joints[KinectAzure.K4ABT_JOINT_PELVIS];
                  outputCtx.fillStyle = 'green';
                  outputCtx.fillRect(pelvis.colorX, pelvis.colorY, 10, 10);
                });
                outputCtx.restore();
              }
            });
          }
        };

        const renderBGRA32ColorFrame = (ctx, canvasImageData, imageFrame) => {
          const newPixelData = Buffer.from(imageFrame.imageData);
          const pixelArray = canvasImageData.data;
          for (let i = 0; i < canvasImageData.data.length; i+=4) {
            pixelArray[i] = newPixelData[i+2];
            pixelArray[i+1] = newPixelData[i+1];
            pixelArray[i+2] = newPixelData[i];
            pixelArray[i+3] = 0xff;
          }
          ctx.putImageData(canvasImageData, 0, 0);
        };

        const animate = () => {
          statsRenderer.update();
          requestAnimationFrame( animate );
        }

        // expose the kinect instance to the window object in this demo app to allow the parent window to close it between sessions
        window.kinect = kinect;
        init();
      }
    </script>
  </body>
</html>